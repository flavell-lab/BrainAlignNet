{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46887e80-a42a-4dcb-a1fb-4b341d6428bb",
   "metadata": {},
   "source": [
    "### training the BrainAlignNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "411d238e-8eb0-4458-ba04-6e1fe991d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import set_GPU, fit_deepreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "876dd785-f5e0-46a4-adad-d84b474cec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base = \"/scratch/nar8991/computer_vision/BrainAlignNet\"\n",
    "# config_path = f\"{base}/demo_network_config.yaml\"\n",
    "# log_dir = f\"{base}/demo_notebook\"\n",
    "# experiment_name = \"Atanas_processed\" # This is also the name of the dataset\n",
    "# max_epochs = 2\n",
    "# initial_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eb63363-0ada-4218-8277-8df5670a69b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/scratch/nar8991/computer_vision/BrainAlignNet\"\n",
    "config_path = f\"{base}/demo_network_config_EY_adjusted.yaml\"\n",
    "log_dir = f\"{base}/demo_notebook_EY\"\n",
    "experiment_name = \"EY\" # This is also the name of the dataset\n",
    "max_epochs = 2\n",
    "initial_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab08a3e2-f81d-4289-888e-f95fa1af257c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "133ef7e6-f4f1-4edf-a529-a69b9a87eb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15345c06-f6ff-4c7a-b56e-ee874cd029d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8b2f318-8fce-43fa-b8b5-7510e883ad30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 107to593, Shape: (177, 3)\n",
      "Dataset: 118to229, Shape: (177, 3)\n",
      "Dataset: 128to184, Shape: (177, 3)\n",
      "Dataset: 163to841, Shape: (177, 3)\n",
      "Dataset: 170to279, Shape: (177, 3)\n",
      "Dataset: 187to194, Shape: (177, 3)\n",
      "Dataset: 208to637, Shape: (177, 3)\n",
      "Dataset: 221to403, Shape: (177, 3)\n",
      "Dataset: 227to129, Shape: (177, 3)\n",
      "Dataset: 267to224, Shape: (177, 3)\n",
      "Dataset: 271to260, Shape: (177, 3)\n",
      "Dataset: 280to916, Shape: (177, 3)\n",
      "Dataset: 282to40, Shape: (177, 3)\n",
      "Dataset: 285to248, Shape: (177, 3)\n",
      "Dataset: 378to664, Shape: (177, 3)\n",
      "Dataset: 388to615, Shape: (177, 3)\n",
      "Dataset: 399to906, Shape: (177, 3)\n",
      "Dataset: 3to264, Shape: (177, 3)\n",
      "Dataset: 418to911, Shape: (177, 3)\n",
      "Dataset: 429to62, Shape: (177, 3)\n",
      "Dataset: 435to419, Shape: (177, 3)\n",
      "Dataset: 442to481, Shape: (177, 3)\n",
      "Dataset: 467to837, Shape: (177, 3)\n",
      "Dataset: 468to771, Shape: (177, 3)\n",
      "Dataset: 470to460, Shape: (177, 3)\n",
      "Dataset: 49to464, Shape: (177, 3)\n",
      "Dataset: 515to307, Shape: (177, 3)\n",
      "Dataset: 572to465, Shape: (177, 3)\n",
      "Dataset: 577to752, Shape: (177, 3)\n",
      "Dataset: 586to8, Shape: (177, 3)\n",
      "Dataset: 58to819, Shape: (177, 3)\n",
      "Dataset: 631to296, Shape: (177, 3)\n",
      "Dataset: 657to448, Shape: (177, 3)\n",
      "Dataset: 666to824, Shape: (177, 3)\n",
      "Dataset: 670to301, Shape: (177, 3)\n",
      "Dataset: 694to513, Shape: (177, 3)\n",
      "Dataset: 704to574, Shape: (177, 3)\n",
      "Dataset: 70to868, Shape: (177, 3)\n",
      "Dataset: 716to809, Shape: (177, 3)\n",
      "Dataset: 742to749, Shape: (177, 3)\n",
      "Dataset: 75to387, Shape: (177, 3)\n",
      "Dataset: 760to907, Shape: (177, 3)\n",
      "Dataset: 789to149, Shape: (177, 3)\n",
      "Dataset: 804to785, Shape: (177, 3)\n",
      "Dataset: 836to876, Shape: (177, 3)\n",
      "Dataset: 87to823, Shape: (177, 3)\n",
      "Dataset: 891to892, Shape: (177, 3)\n",
      "Dataset: 910to272, Shape: (177, 3)\n",
      "Dataset: 923to711, Shape: (177, 3)\n",
      "Dataset: 95to889, Shape: (177, 3)\n"
     ]
    }
   ],
   "source": [
    "# Centroid Labeler does not determine this\n",
    "import h5py\n",
    "\n",
    "# Path to your .h5 file\n",
    "file_path = '/scratch/nar8991/computer_vision/data/EY/test/nonaugmented/20190925-04/moving_labels.h5'\n",
    "\n",
    "# Open the file in read-only mode\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    # Iterate through the datasets to check their shapes\n",
    "    for dataset_name in f:\n",
    "        dataset = f[dataset_name]\n",
    "        print(f\"Dataset: {dataset_name}, Shape: {dataset.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d90553f9-821c-4069-9c0f-2cff5fe852a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-12-04 19:00:15 | WARNING  | Log directory /scratch/nar8991/computer_vision/BrainAlignNet/demo_notebook_EY/EY exists already.\n",
      "Built inputs.\n",
      "Built control points.\n",
      "Concatenated images.\n",
      "{'extract_levels': ListWrapper([0, 1, 2, 3]), 'name': 'local', 'num_channel_initial': 16}\n",
      "Built backbone.\n",
      "Built DDF.\n",
      "Built warping.\n",
      "Built outputs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-04 19:00:19.614565: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-12-04 19:00:36.697169: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2024-12-04 19:00:37.523124: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-12-04 19:00:50.850891: I external/local_xla/xla/service/service.cc:168] XLA service 0x14cb735489a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-04 19:00:50.850909: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): Quadro RTX 8000, Compute Capability 7.5\n",
      "2024-12-04 19:00:50.859744: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733356851.097946 3537603 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "12/12 [==============================] - 26s 2s/step - loss: nan - metric/moving_image_mean: 0.0281 - metric/moving_image_min: 0.0000e+00 - metric/moving_image_max: 1.0000 - metric/fixed_image_mean: 0.0280 - metric/fixed_image_min: 0.0000e+00 - metric/fixed_image_max: 1.0000 - loss/image_LocalNormalizedCrossCorrelationLoss: nan - loss/image_LocalNormalizedCrossCorrelationLoss_weighted: nan - metric/moving_label_mean: 47.9084 - metric/moving_label_min: -1.0000 - metric/moving_label_max: 237.4541 - metric/fixed_label_mean: 47.9888 - metric/fixed_label_min: -1.0000 - metric/fixed_label_max: 239.4827 - loss/label_CentroidDistance: nan - loss/label_CentroidDistance_weighted: nan - loss/regularization_HybridNorm: nan - loss/regularization_HybridNorm_weighted: nan - metric/ddf_mean: nan - metric/ddf_min: nan - metric/ddf_max: nan - val_loss: nan - val_metric/moving_image_mean: 0.0258 - val_metric/moving_image_min: 0.0000e+00 - val_metric/moving_image_max: 1.0000 - val_metric/fixed_image_mean: 0.0257 - val_metric/fixed_image_min: 0.0000e+00 - val_metric/fixed_image_max: 1.0000 - val_loss/image_LocalNormalizedCrossCorrelationLoss: nan - val_loss/image_LocalNormalizedCrossCorrelationLoss_weighted: nan - val_metric/moving_label_mean: 49.0414 - val_metric/moving_label_min: -1.0000 - val_metric/moving_label_max: 234.8125 - val_metric/fixed_label_mean: 49.0535 - val_metric/fixed_label_min: -1.0000 - val_metric/fixed_label_max: 234.7500 - val_loss/label_CentroidDistance: nan - val_loss/label_CentroidDistance_weighted: nan - val_loss/regularization_HybridNorm: nan - val_loss/regularization_HybridNorm_weighted: nan - val_metric/ddf_mean: nan - val_metric/ddf_min: nan - val_metric/ddf_max: nan\n",
      "Epoch 2/2\n",
      "12/12 [==============================] - 22s 2s/step - loss: nan - metric/moving_image_mean: 0.0285 - metric/moving_image_min: 0.0000e+00 - metric/moving_image_max: 1.0000 - metric/fixed_image_mean: 0.0285 - metric/fixed_image_min: 0.0000e+00 - metric/fixed_image_max: 1.0000 - loss/image_LocalNormalizedCrossCorrelationLoss: nan - loss/image_LocalNormalizedCrossCorrelationLoss_weighted: nan - metric/moving_label_mean: 47.8543 - metric/moving_label_min: -1.0000 - metric/moving_label_max: 239.3336 - metric/fixed_label_mean: 47.8216 - metric/fixed_label_min: -1.0000 - metric/fixed_label_max: 239.1527 - loss/label_CentroidDistance: nan - loss/label_CentroidDistance_weighted: nan - loss/regularization_HybridNorm: nan - loss/regularization_HybridNorm_weighted: nan - metric/ddf_mean: nan - metric/ddf_min: nan - metric/ddf_max: nan - val_loss: nan - val_metric/moving_image_mean: 0.0258 - val_metric/moving_image_min: 0.0000e+00 - val_metric/moving_image_max: 1.0000 - val_metric/fixed_image_mean: 0.0257 - val_metric/fixed_image_min: 0.0000e+00 - val_metric/fixed_image_max: 1.0000 - val_loss/image_LocalNormalizedCrossCorrelationLoss: nan - val_loss/image_LocalNormalizedCrossCorrelationLoss_weighted: nan - val_metric/moving_label_mean: 49.0414 - val_metric/moving_label_min: -1.0000 - val_metric/moving_label_max: 234.8125 - val_metric/fixed_label_mean: 49.0535 - val_metric/fixed_label_min: -1.0000 - val_metric/fixed_label_max: 234.7500 - val_loss/label_CentroidDistance: nan - val_loss/label_CentroidDistance_weighted: nan - val_loss/regularization_HybridNorm: nan - val_loss/regularization_HybridNorm_weighted: nan - val_metric/ddf_mean: nan - val_metric/ddf_min: nan - val_metric/ddf_max: nan\n"
     ]
    }
   ],
   "source": [
    "set_GPU(0)\n",
    "fit_deepreg(\n",
    "    config_path,\n",
    "    log_dir,\n",
    "    experiment_name,\n",
    "    max_epochs,\n",
    "    initial_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d443ae1b-29e7-4433-8125-885312eda217",
   "metadata": {},
   "source": [
    "### register test (unseen) images with checkpoint (weights of the trained network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76aaebd-300d-4728-b6be-4c6fcf913c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from register import set_GPU, register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945b047c-0eef-4a09-b6a5-f17efeb190ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"/scratch/nar8991/computer_vision/BrainAlignNet\"\n",
    "config_path = f\"{base}/demo_network_config.yaml\"\n",
    "log_dir = f\"{base}/demo_notebook\"\n",
    "experiment_name = \"Atanas_processed\" # This is also the name of the dataset\n",
    "max_epochs = 2\n",
    "initial_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85321c-ea87-4b1f-befa-0c981105ada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config_path = f\"{base}/demo_network_config.yaml\"\n",
    "model_ckpt_path = f\"{base}/demo_notebook/test_full_network/save/ckpt-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a6b344-1bc3-4691-b007-346bc7d7e0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_GPU(0)\n",
    "registered_outputs = register(model_config_path, model_ckpt_path, 'test', log_dir, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9566d291-b1fa-4418-bc55-796b359fc143",
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7ba635-3896-4db8-ba71-b0308568f806",
   "metadata": {},
   "source": [
    "#### plot registered outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594340e0-f306-471e-bd6d-ba0f85a95d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a38bd6-92fe-4260-85c9-047e71ddc67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_path = os.path.join(log_dir, 'registered_outputs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b280211d-e910-4653-9e68-64db6d497532",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26f2690-f9ef-45c7-881e-f9e965a63d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(final_path, 'wb') as f:\n",
    "    pickle.dump(registered_outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09a9441-203b-4852-81a4-c464c8b65ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure it saved properly\n",
    "with open(final_path, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64695cfe-8660-4482-9a53-ee632cc23506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pickleability(registered_outputs):\n",
    "    non_pickleable = []\n",
    "    \n",
    "    for key, value in registered_outputs.items():\n",
    "        try:\n",
    "            # Try to pickle the value to a temporary file or buffer\n",
    "            with open(f'{key}.pkl', 'wb') as f:\n",
    "                pickle.dump(value, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            print(f\"{key}: Pickleable\")\n",
    "        except Exception as e:\n",
    "            print(f\"{key}: Not pickleable (Error: {e})\")\n",
    "            non_pickleable.append((key, value))\n",
    "    \n",
    "    return non_pickleable\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96bf98a-7634-4aec-b7dd-815e7c786d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pickleability(registered_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec9635a-f8ad-4538-a3dd-41f7c32179bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3e5c1-b4d1-4e09-9d42-e3a30ebbcb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_outputs['2022-04-14-04'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91a22ee-6f76-46a4-a6bf-bd21fccc46f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These keys are slightly different because of how I got the test data this time around/various versions vs. what was reported in Atanas (NR)\n",
    "output_dict = registered_outputs['2022-04-14-04']['1003to1469']\n",
    "warped_moving_image = output_dict['warped_moving_image']\n",
    "warped_moving_roi = output_dict['warped_moving_roi']\n",
    "warped_moving_centroids = output_dict['warped_moving_centroids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe2789b-5aac-418c-887d-47062d2c14e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_moving_image.shape, warped_moving_roi.shape, warped_moving_centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c62ff6-11ce-4b8d-b225-96f07c72c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 12))\n",
    "axes[0].imshow(warped_moving_image.max(2));\n",
    "axes[0].set_title(\"warped moving image\", fontsize=20);\n",
    "axes[1].imshow(warped_moving_roi.max(2));\n",
    "axes[1].set_title(\"warped moving roi\", fontsize=20);\n",
    "\n",
    "axes[2].imshow(warped_moving_roi.max(2));\n",
    "axes[2].set_title(\"warped moving roi\", fontsize=20);\n",
    "\n",
    "xs = [x for (x, _, _) in warped_moving_centroids]\n",
    "ys = [y for (_, y, _) in warped_moving_centroids]\n",
    "\n",
    "\n",
    "axes[2].scatter(ys, xs, s=5, c='w');\n",
    "axes[2].set_title(\"warped moving centroids\", fontsize=20);\n",
    "axes[2].set_xlim(0, 120);\n",
    "axes[2].set_ylim(0, 284);\n",
    "axes[2].invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab57a15-8304-4bbd-8e51-457965ac4de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These keys are slightly different because of how I got the test data this time around/various versions vs. what was reported in Atanas (NR)\n",
    "output_dict = loaded_data['2022-04-14-04']['1003to1469']\n",
    "warped_moving_image = output_dict['warped_moving_image']\n",
    "warped_moving_roi = output_dict['warped_moving_roi']\n",
    "warped_moving_centroids = output_dict['warped_moving_centroids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4af047-6f07-4516-9658-abddc040ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "warped_moving_image.shape, warped_moving_roi.shape, warped_moving_centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e11fc1-780a-4061-97c4-cf2e7bb82205",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 12))\n",
    "axes[0].imshow(warped_moving_image.max(2));\n",
    "axes[0].set_title(\"warped moving image\", fontsize=20);\n",
    "axes[1].imshow(warped_moving_roi.max(2));\n",
    "axes[1].set_title(\"warped moving roi\", fontsize=20);\n",
    "\n",
    "axes[2].imshow(warped_moving_roi.max(2));\n",
    "axes[2].set_title(\"warped moving roi\", fontsize=20);\n",
    "\n",
    "xs = [x for (x, _, _) in warped_moving_centroids]\n",
    "ys = [y for (_, y, _) in warped_moving_centroids]\n",
    "\n",
    "\n",
    "axes[2].scatter(ys, xs, s=5, c='w');\n",
    "axes[2].set_title(\"warped moving centroids\", fontsize=20);\n",
    "axes[2].set_xlim(0, 120);\n",
    "axes[2].set_ylim(0, 284);\n",
    "axes[2].invert_yaxis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "julia_works",
   "language": "python",
   "name": "julia_works"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
